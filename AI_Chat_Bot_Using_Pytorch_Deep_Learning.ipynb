{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.11"
    },
    "colab": {
      "name": "AI Chat Bot Using Pytorch Deep Learning.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8PH1TTNccUZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "f27fe65a-88c1-47c1-ca0e-f5339d07e9e0"
      },
      "source": [
        "import numpy as np\n",
        "!pip install import-ipynb\n",
        "import import_ipynb\n",
        "!pip install ipynb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting import-ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=5389dc478f5f6e2ab727190d96fc6791eebc661ccd20dfd0742a57814eb5414c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n",
            "Collecting ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/31/42/4c0bbb66390e3a68e04ebf134c8d074a00c18b5882293f8ace5f7497fbf0/ipynb-0.5.1-py3-none-any.whl\n",
            "Installing collected packages: ipynb\n",
            "Successfully installed ipynb-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf4dV7KQccUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a7aed14f-515b-4148-8da4-4f427eb40c91"
      },
      "source": [
        "import torch\n",
        "import json\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import nltk\n",
        "#from nltk_utils import get_ipython\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "stemmer=PorterStemmer()\n",
        "\n",
        "def tokenize(sentence):\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "def stemming(word):\n",
        "    return stemmer.stem(word.lower())\n",
        "\n",
        "def bagofwords(tokenized_sentence,all_words):\n",
        "    tokenized_sentence=[stemming(w) for w in tokenized_sentence]\n",
        "    bag=np.zeros(len(all_words),dtype=np.float32)\n",
        "    for index,word in enumerate(all_words):\n",
        "        if word in tokenized_sentence:\n",
        "            bag[index]=1.0\n",
        "    return bag        \n",
        "    \n",
        "    \n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm-E2L_xccUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"intents1.json\",\"r\") as f:\n",
        "    intents=json.load(f)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxXW86-LccUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_words=[]\n",
        "tags=[]\n",
        "xy=[]\n",
        "for intent in intents[\"intents\"]:\n",
        "    tags.append(intent[\"tag\"])\n",
        "    for sentence in intent[\"patterns\"]:\n",
        "        words=tokenize(sentence)\n",
        "        all_words.extend(words)\n",
        "        xy.append((words,intent[\"tag\"]))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdFqmTACccUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ignore_words=[\"?\",\".\",\",\",\"!\"]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwjiRJWEccUs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9b88795c-0fe3-431d-992c-09c8917b10cd"
      },
      "source": [
        "all_words=[stemming(word) for word in all_words if word not in ignore_words]\n",
        "len(all_words)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGXsUdFpccUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_words=sorted(set(all_words))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3G5sZxCccUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7dc025a7-2e27-4bd8-b7a2-ad70689c7f62"
      },
      "source": [
        "tags=sorted(tags)\n",
        "tags"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['delivery', 'funny', 'goodbye', 'greeting', 'items', 'payments', 'thanks']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbsUF1OyccU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=[]\n",
        "y_train=[]\n",
        "for (sentence,tag) in xy:\n",
        "    bag=bagofwords(sentence,all_words)\n",
        "    X_train.append(bag)\n",
        "    label=tags.index(tag)\n",
        "    y_train.append(label)\n",
        "    \n",
        "X_train=np.array(X_train)\n",
        "y_train=np.array(y_train)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXpn76MyccU6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "81cd9971-755d-483d-ec11-4a76a5505245"
      },
      "source": [
        "X_train\n",
        "y_train"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 3, 3, 3, 2, 2, 2, 6, 6, 6, 6, 4, 4, 4, 5, 5, 5, 5, 0, 0,\n",
              "       0, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7Y7k0c6ccU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BotDataset:\n",
        "    def __init__(self):\n",
        "        self.num_samples=len(X_train)\n",
        "        self.x_data=X_train\n",
        "        self.y_data=y_train\n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "        return self.x_data[index],self.y_data[index]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.num_samples"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5uzAi5pccVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=BotDataset()\n",
        "train_loader=DataLoader(dataset=dataset,batch_size=4,shuffle=True,num_workers=2)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLi0YbStccVG",
        "colab_type": "text"
      },
      "source": [
        "### Model Bulding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ75XXv5ccVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self,input_size,size_l1,size_l2,size_l3,num_classes):\n",
        "        super().__init__()\n",
        "        self.l1=nn.Linear(input_size,size_l1)\n",
        "        self.l2=nn.Linear(size_l1,size_l2)\n",
        "        self.l3=nn.Linear(size_l2,size_l3)\n",
        "        self.l4=nn.Linear(size_l3,num_classes)\n",
        "        self.relu=nn.ReLU()\n",
        "        \n",
        "    def forward(self,x):\n",
        "        output=self.l1(x)\n",
        "        output=self.relu(output)\n",
        "        output=self.l2(output)\n",
        "        output=self.relu(output)\n",
        "        output=self.l3(output)\n",
        "        output=self.relu(output)\n",
        "        output=self.l4(output)\n",
        "        return output\n",
        "        \n",
        "            \n",
        "        "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmeTAmQ-ccVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=NeuralNet(len(all_words),10,20,10,len(tags))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJk2_Q0lccVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "10bb677a-b3d2-4c69-8e72-157ab12218ba"
      },
      "source": [
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "num_epochs=400\n",
        "train_loader"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f95f82289e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRvc3isZccVT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "305884a6-075e-45ee-a25c-040b920eda21"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for (words,label) in train_loader:\n",
        "        pred=model.forward(words)\n",
        "        loss=criterion(pred,label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    if epoch%10==0:\n",
        "        print(\"epoch: {} and loss: {}\".format(epoch,loss.item()))\n",
        "    \n",
        "    "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 and loss: 1.749819040298462\n",
            "epoch: 10 and loss: 1.7998692989349365\n",
            "epoch: 20 and loss: 2.1232807636260986\n",
            "epoch: 30 and loss: 1.4061774015426636\n",
            "epoch: 40 and loss: 1.4614498615264893\n",
            "epoch: 50 and loss: 0.6012253165245056\n",
            "epoch: 60 and loss: 0.2649418115615845\n",
            "epoch: 70 and loss: 0.08440493047237396\n",
            "epoch: 80 and loss: 0.13002842664718628\n",
            "epoch: 90 and loss: 0.009104873053729534\n",
            "epoch: 100 and loss: 0.0523400716483593\n",
            "epoch: 110 and loss: 0.021827595308423042\n",
            "epoch: 120 and loss: 0.008811363950371742\n",
            "epoch: 130 and loss: 0.006072648335248232\n",
            "epoch: 140 and loss: 0.0017492328770458698\n",
            "epoch: 150 and loss: 0.010148456320166588\n",
            "epoch: 160 and loss: 0.006226967088878155\n",
            "epoch: 170 and loss: 0.0017255402635782957\n",
            "epoch: 180 and loss: 0.0016604505944997072\n",
            "epoch: 190 and loss: 0.0034376392140984535\n",
            "epoch: 200 and loss: 0.003710213117301464\n",
            "epoch: 210 and loss: 0.0029225756879895926\n",
            "epoch: 220 and loss: 0.0022174331825226545\n",
            "epoch: 230 and loss: 0.000758479000069201\n",
            "epoch: 240 and loss: 0.0005955668166279793\n",
            "epoch: 250 and loss: 0.0009354195790365338\n",
            "epoch: 260 and loss: 0.0011572949588298798\n",
            "epoch: 270 and loss: 0.001668445416726172\n",
            "epoch: 280 and loss: 0.000998301082290709\n",
            "epoch: 290 and loss: 0.0008672322146594524\n",
            "epoch: 300 and loss: 0.0009387393947690725\n",
            "epoch: 310 and loss: 0.000555829203221947\n",
            "epoch: 320 and loss: 0.00030119079747237265\n",
            "epoch: 330 and loss: 0.0010017934255301952\n",
            "epoch: 340 and loss: 0.0012785876169800758\n",
            "epoch: 350 and loss: 0.0010712477378547192\n",
            "epoch: 360 and loss: 0.0004889745032414794\n",
            "epoch: 370 and loss: 0.00024136563297361135\n",
            "epoch: 380 and loss: 0.0007615050999447703\n",
            "epoch: 390 and loss: 9.09513037186116e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCKHn0LEccVW",
        "colab_type": "text"
      },
      "source": [
        "### Implementing Chat Bot "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mw2ajp0ccVX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "2248b9c3-a568-4d8f-d60f-3b7800cbcb95"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (l1): Linear(in_features=54, out_features=10, bias=True)\n",
              "  (l2): Linear(in_features=10, out_features=20, bias=True)\n",
              "  (l3): Linear(in_features=20, out_features=10, bias=True)\n",
              "  (l4): Linear(in_features=10, out_features=7, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT4ErcgzccVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model\n",
        "import random"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_-EVLUogo8o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "67be342e-f5b6-4659-e187-a94f6746ebd9"
      },
      "source": [
        "bot_name = \"Saket\"\n",
        "print(\"Let's chat! (type 'q' to exit)\")\n",
        "while True:\n",
        "\n",
        "    # sentence = \"do you use credit cards?\"\n",
        "    sentence = input(\"You: \")\n",
        "    if sentence == \"q\":\n",
        "        break\n",
        "\n",
        "    sentence = tokenize(sentence)\n",
        "    X = bagofwords(sentence, all_words)\n",
        "    X = X.reshape(1, X.shape[0])\n",
        "    X = torch.from_numpy(X)\n",
        "\n",
        "    output = model(X)\n",
        "    _, predicted = torch.max(output, dim=1)\n",
        "\n",
        "    tag = tags[predicted.item()]\n",
        "\n",
        "    probs = torch.softmax(output, dim=1)\n",
        "    prob = probs[0][predicted.item()]\n",
        "    if prob.item() > 0.5:\n",
        "        for intent in intents['intents']:\n",
        "            if tag == intent[\"tag\"]:\n",
        "                print(\"{} :{}\".format(bot_name,random.choice(intent[\"responses\"])))\n",
        "    else:\n",
        "        print(f\"{bot_name}: I do not understand...\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's chat! (type 'q' to exit)\n",
            "You: Hey\n",
            "Saket :Hey :-)\n",
            "You: what do you sell?\n",
            "Saket :We sell coffee and tea\n",
            "You: I want to order\n",
            "Saket :My pleasure\n",
            "You: i want to order tea\n",
            "Saket :Happy to help!\n",
            "You: how can I order?\n",
            "Saket :Any time!\n",
            "You: do you accept cash?\n",
            "Saket :We accept most major credit cards, and Paypal\n",
            "You: i will pay by credit card\n",
            "Saket :We accept most major credit cards, and Paypal\n",
            "You: okay\n",
            "Saket: I do not understand...\n",
            "You: thank you\n",
            "Saket :Any time!\n",
            "You: see you\n",
            "Saket :Have a nice day\n",
            "You: bye\n",
            "Saket :Bye! Come back again soon.\n",
            "You: take care\n",
            "Saket :My pleasure\n",
            "You: q\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN03cATlp975",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hi\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}